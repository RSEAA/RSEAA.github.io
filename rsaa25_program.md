---
layout: default
title: RSAA25 Conference Program
permalink: /rsaa25_program
navigation_weight: 1
---

# Program
*Note: All times in this program are displayed in UTC +10 (Australian Eastern Standard Time).*

## Day 1 – Wednesday 17 September

### Workshops | 12:30–16:45

| Time        | Length | Session Title                                                                                                                | Presenter(s)                     | Type     |
| ----------- | ------ | ---------------------------------------------------------------------------------------------------------------------------- | --------------------------------- | -------- |
| [12:30–12:35](https://www.timeanddate.com/worldclock/fixedtime.html?iso=20250917T0230) | 5 min  | Welcome & Introduction                                                                                                       | RSAA Organisers                   | Intro    |
| [12:35–13:20](https://www.timeanddate.com/worldclock/fixedtime.html?iso=20250917T0235) | 45 min | [Why connect your service to the Australian Access Federation](#why-connect-your-service-to-the-australian-access-federation) | Terry Smith (AAF)                 | Workshop |
| [13:20–13:25](https://www.timeanddate.com/worldclock/fixedtime.html?iso=20250917T0320) | 5 min  | Break                                                                                                                         | —                                | Break    |
| [13:25–14:25](https://www.timeanddate.com/worldclock/fixedtime.html?iso=20250917T0325) | 60 min | [Kubernetes for Scalable Research: An Introduction](#kubernetes-for-scalable-research-an-introduction)                       | Aleem Uddin (ARDC)               | Workshop |
| [14:25–14:30](https://www.timeanddate.com/worldclock/fixedtime.html?iso=20250917T0425) | 5 min  | Break                                                                                                                         | —                                | Break    |
| 14:30–15:30 | 60 min | [Developer’s Guide to GitHub Copilot: Supercharging Research Software Development](#developers-guide-to-github-copilot-supercharging-research-software-development) | Ayodeji Ayodele (GitHub)         | Workshop |
| 15:30–15:35 | 5 min  | Break                                                                                                                         | —                                | Break    |
| 15:35–16:35 | 60 min | Parallel Workshops:<br>• [Quick Tips for Making Your Software Outlive Your Job](#quick-tips-for-making-your-software-outlive-your-job)<br>• [Metavaluation: A Participatory Experiment in Valuing Diverse Contributions to RSAA](#metavaluation-a-participatory-experiment-in-valuing-diverse-contributions-to-rsaa) | Richard Littauer<br><br>Cooper Smout  | Workshop |
| 16:35–16:45 | 10 min | Conference Day 1 Closing                                                                                                      | RSAA Organisers                  | Closing  |

<br/><br/>
---

## Day 2 – Thursday 18 September

**Keynote & Talks** | 12:30–16:45

| Time        | Length | Session Title                                                                                           | Presenter(s)    | Type    |
| ----------- | ------ | ------------------------------------------------------------------------------------------------------- | --------------- | ------- |
| 12:30–13:00 | 30 min | Welcome, Introduction & Gold Partners Acknowledgement                                                   | RSAA Organisers | Intro   |
| 13:00–13:30 | 30 min | [IQ-TREE – Software for Evolutionary Biology with Genomics Data](#iq-tree-software-for-evolutionary-biology-with-genomics-data) | Minh Bui        | Keynote |

### Parallel Sessions (Block 1 & Block 2) | 13:30–15:00

| **Block 1: Sustainability & Community Building**                                                                                                                   | **Block 2: Infrastructure & Resources**                                                                                                                 |
| ---------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **13:30–13:45**<br>[Building Emotional Infrastructure for OSS Communities](#building-emotional-infrastructure-for-oss-communities)<br>Laura Langdon                   | **13:30–13:45**<br>[Highly Reproducible R Environments with Nix](#highly-reproducible-r-environments-with-nix)<br>Justin Bedo                             |
| **13:45–14:00**<br>[ADACS: Lessons Learned on the Road to a New Model for Creating and Maintaining Research Software](#adacs-lessons-learned-on-the-road-to-a-new-model-for-creating-and-maintaining-research-software)<br>Gregory B. Poole | **13:45–14:00**<br>[REDMANE: A Lightweight Ecosystem for Research Data Management across Organisations and Diverse Data Types](#redmane-a-lightweight-ecosystem-for-research-data-management-across-organisations-and-diverse-data-types)<br>Rowland Mosbergen |
| **14:00–14:15**<br>[ConveRSE – Let's Talk About Mental Health](#converse-lets-talk-about-mental-health)<br>Mike Simpson                                            | **14:00–14:15**<br>[Building a National Dataspace Testbed: Infrastructure Foundations for Trusted Data Exchange in Australia](#building-a-national-dataspace-testbed-infrastructure-foundations-for-trusted-data-exchange-in-australia)<br>Dr Robert Shen |
| **14:15–14:30**<br>[Building Capability in RSE for the Humanities and Social Sciences (HASS)](#building-capability-in-rse-for-the-humanities-and-social-sciences-hass)<br>James Smithies, Peter Sefton  | **14:15–14:30**<br>[The Big Switch: AURIN's Pivot from Portal to Platform](#the-big-switch-aurins-pivot-from-portal-to-platform)<br>Dr Loren Bruns Jr        |
| **14:30–14:45**<br>[No User Left Behind: How to ensure your research software is accessible and inclusive](#no-user-left-behind-how-to-ensure-your-research-software-is-accessible-and-inclusive)<br>Asher Leslie  | **14:30–14:45**<br>[Modernising Urban Research with Traefik Modular Access Gateway](#modernising-urban-research-with-traefik-modular-access-gateway)<br>German Eduardo Gonzalez |
| **14:45–14:55**<br>Q&A (Block 1) —                                                                                                                                | **14:45–14:55**<br>[AURIN's Internal Developer Platform](#aurins-internal-developer-platform)<br>Muhammad Umer Altaf                                    |
|                                                                                                                                                                  | **14:55–15:00**<br>Q&A (Block 2) —                                                                                                                     |

---

### Parallel Sessions (Block 3 & Block 4) | 15:00–16:35

| **Block 3: Collaboration & Data Science**                                                                                                            | **Block 4: Research Applications & Governance**                                                                                             |
| --------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- |
| **15:00–15:15**<br>[Pipelines and people: Reproducible research with Nextflow and the nf-core community](#pipelines-and-people-reproducible-research-with-nextflow-and-the-nf-core-community)<br>Christopher Hakkaart   | **15:00–15:15**<br>[Metavaluation: A Participatory Framework for Recognising, Rewarding, and Coordinating What Matters](#metavaluation-a-participatory-framework-for-recognising-rewarding-and-coordinating-what-matters)<br>Cooper Smout   |
| **15:15–15:30**<br>[H5Pydantic, an ORM for HDF5 files](#h5pydantic-an-orm-for-hdf5-files)<br>Clinton Roy                                             | **15:15–15:30**<br>[Bridging Climate Science and Collaboration Through Software tools at the Global km-Scale Hackathon](#bridging-climate-science-and-collaboration-through-software-tools-at-the-global-km-scale-hackathon)<br>Paola Corrales  |
| **15:30–15:45**<br>[Federated Learning - Why, what, how, where to.](#federated-learning-why-what-how-where-to)<br>Peter Marendy                     | **15:30–15:45**<br>[Developing Australia’s first epidemic forecasting hub](#developing-australias-first-epidemic-forecasting-hub)<br>Katharine Senior                                |
| **15:45–16:00**<br>[AI-assisted Humanities Researcher Workbenches](#ai-assisted-humanities-researcher-workbenches)<br>Dr Ian McCrabb                  | **15:45–16:00**<br>[Piloting peer code review in a research consortium community of practice](#piloting-peer-code-review-in-a-research-consortium-community-of-practice)<br>Saras Windecker, Rob Moss  |
| **16:00–16:15**<br>[Metrics to Music: Where AI Meets Digital Classic](#metrics-to-music-where-ai-meets-digital-classic)<br>Sree Ganesh Thottempudi     | **16:00–16:15**<br>[Bridging Governance, Access, and Technology Issues in Health: A Sociotechnical View from the Philippines](#bridging-governance-access-and-technology-issues-in-health-a-sociotechnical-view-from-the-philippines)<br>Dennis B. Batangan  |
| **16:15–16:25**<br>[Towards Scalable Biocuration Workflows for Biomedical Research Data Management](#towards-scalable-biocuration-workflows-for-biomedical-research-data-management)<br>Sakshi Patel | **16:15–16:25**<br>[A Clearer Path to Secure Authentication: PKCE and OIDC Explained](#a-clearer-path-to-secure-authentication-pkce-and-oidc-explained)<br>Matthew Puku           |
| **16:25–16:35**<br>Q&A (Block 3) —                                                                                                                  | **16:25–16:35**<br>Q&A (Block 4) —                                                                                                      |

---

**Closing Remarks**

| Time        | Title   | Presenter(s)    |
| ----------- | ------- | --------------- |
| 16:35–16:45 | Closing | RSAA Organisers |

<br/><br/>
---

## Day 3 – Friday 19 September

**Flexible Format, BoF & Talks** | 12:30–16:35

| Time        | Length | Session Title                 | Presenter(s)          | Type  |
| ----------- | ------ | ----------------------------- | --------------------- | ----- |
| 12:30–12:35 | 5 min  | Welcome & Introduction        | RSAA Organisers       | Intro |

### Flexible Format & BoF

| Time        | Title                                                                 | Presenter(s)                          |
| ----------- | --------------------------------------------------------------------- | ------------------------------------ |
| 12:35–13:35 | [Making Space: Celebrating People and Diversity in Research Software](#making-space-celebrating-people-and-diversity-in-research-software)   | WHPC Committee                       |
| 13:35–14:35 | [Best Practices for Portable and Reproducible Accelerated Computing](#best-practices-for-portable-and-reproducible-accelerated-computing)    | Pawsey Supercomputing Research Centre |
| 14:35–14:45 | Break                                                                 | —                                  |

---

### Parallel Sessions (Block 5, Block 6 & Block 7) | 14:45–16:25

| **Block 5: Skills, Training & Digital Accessibility**                                                   | **Block 6: 10-minute Demos**                                                  | **Block 7: 5-minute Lightning Talks**                                     |
| ---------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------- | ------------------------------------------------------------------------- |
| **14:45–15:00**<br>[From PhD to RSE: Training the Next Generation of Research Software Engineers](#from-phd-to-rse-training-the-next-generation-of-research-software-engineers)<br>Paige E. Martin | **14:45–14:55**<br>[Rust for Scientific Computing - It's Good!](#rust-for-scientific-computing-its-good)<br>Dr Emily Kahl | **15:45–15:50**<br>[Laptop to HPC – An 'Underworld' Story of Sustainable, Accessible Scientific Software](#laptop-to-hpc-an-underworld-story-of-sustainable-accessible-scientific-software)<br>Mr. Julian Giordani |
| **15:00–15:15**<br>[Accessible and extensible design for statistical computing on distributions](#accessible-and-extensible-design-for-statistical-computing-on-distributions)<br>Mitchell O'Hara-Wild | **14:55–15:05**<br>[New tool that improves research reproducibility by integrating High Performance Computing with Continuous Integration](#new-tool-that-improves-research-reproducibility-by-integrating-high-performance-computing-with-continuous-integration)<br>Ignatius Menzies | **15:50–15:55**<br>[Write all the things? The process of collaboratively writing papers](#write-all-the-things-the-process-of-collaboratively-writing-papers)<br>Richard Littauer |
| **15:15–15:30**<br>[Cryo-EM Data at Scale: How Collaborative Models Arose Around the World](#cryo-em-data-at-scale-how-collaborative-models-arose-around-the-world)<br>Keiran Nicholas Rowell | **15:05–15:15**<br>[Creating an open-source data processing pipeline for archival research – Lessons learned from the case study on G. V. Vernadsky’s correspondence](#creating-an-open-source-data-processing-pipeline-for-archival-research-lessons-learned-from-the-case-study-on-g-v-vernadskys-correspondence)<br>Michal Racyn | **15:55–16:00**<br>[Connecting Communities Through Accessible Design: Web Graphics in STEM for the Blind and Visually Impaired Individuals](#connecting-communities-through-accessible-design-web-graphics-in-stem-for-the-blind-and-visually-impaired-individuals)<br>Sanchit Ghule |
| **15:30–15:45**<br>[From Bench to GPU: A Biologist’s Journey into Virtualised Cryo-EM Data Processing on Bunya HPC](#from-bench-to-gpu-a-biologists-journey-into-virtualised-cryo-em-data-processing-on-bunya-hpc)<br>Dr. Farrah Blades | **15:15–15:25**<br>[Through the Looking Glass - generating shared understanding using examples](#through-the-looking-glass-generating-shared-understanding-using-examples)<br>Nick Jenkins | **16:00–16:05**<br>[Managing the Data Chaos: How REDMANE and {generatervis} Tackle Complex Research Workflows](#managing-the-data-chaos-how-redmane-and-generatervis-tackle-complex-research-workflows)<br>Jyoti Bhogal |
| **15:45–16:00**<br>[Modernising I/O and parallelisation in the CABLE land surface model](#modernising-io-and-parallelisation-in-the-cable-land-surface-model)<br>Sean Bryan | **15:25–15:35**<br>[Streamlining Genomics Workflows: Navigating Technology and Skill Limitations in Collaborative Development](#streamlining-genomics-workflows-navigating-technology-and-skill-limitations-in-collaborative-development)<br>Sijia Zeng et al. | **16:05–16:10**<br>[What Happens When RSEs Talk? Enabling Better Research Software Together](#what-happens-when-rses-talk-enabling-better-research-software-together)<br>Jyoti Bhogal |
| **16:00–16:15**<br>[biometryassist: Connecting Statistical Tools with Agricultural Research](#biometryassist-connecting-statistical-tools-with-agricultural-research)<br>Sam Rogers | **15:35–15:45**<br>Q&A (Block 6) —                                               | **16:10–16:15**<br>[Ease-of-Use Maturity Model for Research Software in the Life Sciences](#ease-of-use-maturity-model-for-research-software-in-the-life-sciences)<br>Rowland Mosbergen |
| **16:15–16:25**<br>Q&A (Block 5) —                                                                                                   |                                                                             | **16:15–16:25**<br>Q&A (Block 7) —                                             |

---

**Closing Remarks**

| Time        | Title   | Presenter(s)    |
| ----------- | ------- | --------------- |
| 16:25–16:35 | Closing | RSAA Organisers |


<br/><br/>

# Presentation Information

## Keynote

<a id="iq-tree-software-for-evolutionary-biology-with-genomics-data"></a>
**Title:** IQ-TREE – Software for Evolutionary Biology with Genomics Data

**Abstract:** IQ-TREE is an open-source software tool that turns DNA data into robust evolutionary insights. IQ-TREE has been widely used by thousands of researchers and practitioners to understand evolution and biodiversity across many species, ranging from early life forms on Earth to emerging diseases like COVID-19. In this talk, I will share how we approach develop and maintain the software with our users in mind, how we engage with our users and the wider community, and what ongoing challenges we face.

**Presenter Name:** Minh Bui

**Bio:** Minh Bui is an Associate Professor at ANU School of Computing and Leader of the Computational Phylogenomics Lab. His lab works at the interface between Computing, Biology and Statistics, with the motto to enable evolutionary research in the genomic era. He has been awarded Highly Cited Researcher (Clarivate Web of Science), Australian Field Leader in Evolutionary Biology, and the 2023 Australian Research Data Commons Eureka Prize for Excellence in Research Software.

**Author names:** Minh Bui and Robert Lanfear

---

## Invited workship 1

<a id="why-connect-your-service-to-the-australian-access-federation"></a>
**Title:** Why connect your service to the Australian Access Federation

**Abstract:** The Australian Access Federation (AAF) provides trusted access to national and
international research services to enable Australian research and innovation. The
AAF is the national capability for Trust and Identity for research and higher
education, funded in part by the Australian Government’s National Collaborative
Research Infrastructure Strategy (NCRIS), and is governed by Australia’s
universities and leading research institutions. AAF delivers a world-class single sign-
on that allows individuals across organisational boundaries to collaborate and
access online resources within a trusted environment. This allows students, teachers
and researchers to access thousands of teaching and learning services across
separate organisations, with one username and password.
In this session, Terry Smith, Head of Support at the AAF, will outline AAF’s
authentication technology, requirements that should be considered about your
service during its development to enable improved authentication and will provide a
short demonstration on setting up a service in the AAF Test Federation.

**Presenter Name:** Terry Smith

**Bio:** In early 2009, Terry Smith managed the AAF Pilot project that boot-
strapped what is today known as the Australian Access Federation. Terry is
responsible for the ongoing operation of the Federation and for providing
support and training activities to the AAF subscriber community. Terry is an
experienced IT professional who has been working in Identity and Access
Management in the higher education sector for more than 25 years.

**Author names:** Terry Smith (AAF)

---

## Invited workship 2

<a id="kubernetes-for-scalable-research-an-introduction"></a>
**Title:** Kubernetes for Scalable
Research: An Introduction

**Abstract:** The use of containers and Kubernetes has risen in popularity and adoption over recent
years. This popularity is driven by the advantages the technology provides in realising
software stacks as microservices and scaling them to reach a global audience. This adoption
has been enhanced by the advent of cloud computing. Moreover, according to CNCF,
Kubernetes is emerging as the most popular choice for deploying scalable applications in the
cloud. Given this widespread adoption, various national institutions came together to
establish a national Kubernetes service and promote the use of containers in the research
sector. A community of practice called Australian Research Orchestration Services (ARCOS)
was formed in 2020.
This session briefly introduces ARCOS as a community-driven approach in fostering the
adoption of containers and Kubernetes in the research sector.
This session also aims to briefly touch on the concepts of containers and provide an
introduction to Kubernetes fundamentals. These basics, such as the Kubernetes object
model and microservices architecture, are emphasised with the help of coding examples.
The resources and foundational concepts can be leveraged by the audience to further their
understanding and get started using Kubernetes.

**Presenter Name:** Aleem Uddin

**Author names:** Aleem Uddin (ARDC)

---

## Invited workship 3

<a id="developers-guide-to-github-copilot-supercharging-research-software-development"></a>
**Title:** Developer’s Guide to GitHub Copilot: Supercharging Research Software Development

**Abstract:** This workshop introduces researchers and software engineers to GitHub Copilot, an AI-powered coding assistant that can significantly accelerate software development workflows. Participants will explore how Copilot can be used to write, refactor, and document code more efficiently, with a focus on real-world research software scenarios. Through live demonstrations and interactive prompts, attendees will gain practical insights into integrating Copilot into their development environments, understanding its strengths and limitations, and applying it responsibly in collaborative research settings.Whether you're new to GitHub Copilot or looking to deepen your understanding, this session will equip you with the tools and techniques to make the most of AI-assisted development.

**Presenter Name:** Ayodeji Ayodele

**Bio:** Ayodeji Ayodele—known to many as Ayo—is a seasoned architect, software engineer, and DevOps evangelist with over 20 years of experience across industries including Financial Services, Tech, FMCG, Public Sector, and Manufacturing. Currently serving as a Senior Customer Success Architect at GitHub, Ayo helps enterprise clients unlock the full potential of GitHub’s platform to build, ship, and scale software with confidence. He is the author of GitHub Foundations Certification Guide: Essential Skills, Real-World Labs, and Exam Strategies for GitHub Beginners, a comprehensive resource designed to empower developers of all levels to master Git and GitHub. Ayo holds multiple certifications in GitHub Administration, Copilot, Azure, and DevOps, and is passionate about helping teams deliver high-quality software efficiently. When he’s not architecting solutions or mentoring teams, Ayo shares insights on LinkedIn and YouTube, and the GitHub Community on Discussions, inspiring the next generation of developers through practical guidance and open collaboration.

**Author names:** Ayodeji Ayodele (GitHub)

---

## Flexible Presentation Format

<a id="making-space-celebrating-people-and-diversity-in-research-software"></a>
**Title:** Making space: Celebrating people and diversity in Research Software

**Abstract:** Visibility matters. As the Australasia Chapter of Women in High Performance Computing (WHPC+ AusNZ) we aim to raise the visibility and celebrate the successes of underrepresented groups in fields of computational research and research software. Following the theme “Connecting with Community,” focusing on fostering collaboration and engagement within the research software community, WHPC+ welcomes you to join our session where we showcase the incredible community within the Chapter, and discuss how to best grow our ecosystems.

This session will be split into two parts:
1) A ‘showcase’ of lightning talks by Chapter community who are working on research software projects. We’ll aim to spotlight a diverse group of speakers, ideally from a range of different roles and disciplines. 
2) An open discussion around actionable steps our communities can take to create a more diverse and supportive ecosystem for people working in research software.

This session will spotlight some of the interesting work underway by our Chapter members working in research software, and provide a forum for learning from others’ experiences and perspectives. 


**Presenter Name:** We'll have 1-2 members of the WHPC Organising Committee host the session, but can't confirm who exactly until closer to the event. 

The Committee consist of: 
Jana Makar, New Zealand eScience Infrastructure (NeSI);
Aditi Subramanya, Pawsey Supercomputing Research Centre;
Emily Barker, University of Western Australia;
Linda McIver, Australian Data Science Education Institute;
Carina Kemp, Amazon Web Services;
Kiowa Scott-Hurley, Independent;
Kerri Wait, Independent.

**Bio:** The Australasian Chapter of the global organisation Women in High Performance Computing (WHPC) was launched in 2019. The founding organisations are New Zealand eScience Infrastructure (NeSI), NCI Australia, Pawsey Supercomputing Research Centre, Monash University, and Australasian eResearch Organisations (AeRO). Today, the Chapter supports an active Slack community, regular BoFs at conferences, online meetups, and practical resources for organisations to use for creating positive change. We welcome people from all backgrounds and perspectives beyond gender to join our Chapter. We all have a part to play in supporting diversity and inclusion.

For more information, visit https://tinyurl.com/whpcaunz.


**Author names:** Makar, Jana

---

## BoF session

<a id="best-practices-for-portable-and-reproducible-accelerated-computing"></a>
**Title:** Best Practices for Portable and Reproducible Accelerated Computing

**Abstract:** The rapid evolution of accelerated computing has introduced a diverse array of hardware architectures and programming paradigms, offering unprecedented performance and energy efficiency—especially in GPU-based systems. This diversity also presents significant challenges for software developers striving tomaintain portability and reproducibility across platforms. This session explores best practices, strategies and tools that aim to overcome these limitations by promoting portable and reproducible programming practices in GPU-accelerated environments. We will discuss programming models, abstraction layers, workflow design techniques that enable developers to write code once and deploy it across multiple architectures with minimal modification. We will also explore the economy side of software development looking at productivity versus optimal performance and energy efficiency. Participants will hear from experts who have successfully developed portable GPU-based simulation codes in various domains of scientific computing. Through a series of lightning talks, these practitioners will share insights, lessons learned, and practical approaches to balancing performance with portability. The session will conclude with a moderated discussion, inviting attendees to engage with the speakers, share their own experiences, and explore collaborative solutions to common challenges.

**Presenter Name:** Maciej Cytowski, Sarah Beecroft, Emily Kahl, Christopher Harris, Sam Yates

**Author names:** Maciej Cytowski, Sarah Beecroft, Emily Kahl, Christopher Harris, Sam Yates (Pawsey Supercomputing Research Centre)

---

## 5-minute Lightning Talk

<a id="what-happens-when-rses-talk-enabling-better-research-software-together"></a>
**Title:** What Happens When RSEs Talk? Enabling Better Research Software Together

**Abstract:** A six-month-long online community conversation series titled "Enabling Open Science Through Research Code" (https://rse-asia.github.io/RSE_Asia/events.html) was organised jointly by the RSE Asia and RSSE Africa communities from October 2024 to March 2025. Drawing inspiration from CodeRefinery’s (https://coderefinery.org/) training materials, the series was contextualised for the communities in the Global South. Since, in the Global South, the open science movement is comparatively more recognised than the research software engineering (RSE) movement, the message was anchored in the language of open science to broaden reach and engagement among researchers who code.

Each episode featured an open panel discussion on a topic critical to sustainable and reproducible research software practices, such as reproducibility, documentation, and testing. People working in the Asian and African regions or those who had experience working/collabo[rating with researchers from these regions were invited as panellists. To enhance accessibility,  the sessions were recorded and shared with the communities. Each episode was also accompanied by a summary blog post and a curated resource sheet publicly available on Zenodo.

The impact of the series was visible in community engagement, with RSE Asia’s social media (https://www.linkedin.com/company/rse-asia-association/?viewAsMember=true) engagement rate increasing by 71% during the process. The series also enjoyed popularity with a globally distributed audience across varied time zones.

This poster presents the model that was used for organising this Global South focused community initiative, the strategies that were adopted to increase participation and accessibility, and the types of openly licensed outputs that were co-created. Overall, this series is a testament to how cross-regional collaboration and community-driven efforts can effectively promote research software excellence.

**Presenter Name:** Jyoti Bhogal

**Bio:** Jyoti Bhogal is a trained statistician, community builder, and Research Software Engineering (RSE) advocate with a strong foundation in data and open science. A first-generation STEM graduate, Jyoti’s academic journey—from earning multiple merit-based scholarships to completing a Master’s in Statistics—laid the groundwork for her career in research and software. Her curiosity for open-source tools led her to the R community, and eventually into global RSE movements. 
​​As the Co-Lead of the RSE Asia Association, she has played a pioneering role in amplifying the voices and visibility of RSEs in the Asian region. Over the past four years, Jyoti has led numerous community events, cross-continental collaborations, and research studies, including her 2025 SSI Fellowship. Her work reflects a rare blend of technical expertise and empathetic community engagement, consistently advocating for equitable, inclusive, and collaborative research ecosystems in low- and middle-income countries.

**Author names:** Bhogal, Jyoti

---

## 5-minute Lightning Talk

<a id="managing-the-data-chaos-how-redmane-and-generatervis-tackle-complex-research-workflows"></a>
**Title:** Managing the Data Chaos: How REDMANE and {generatervis} Tackle Complex Research Workflows

**Abstract:** Data management is the process of collecting, storing, organising, and using data in a structured manner to ensure accuracy, completeness, and security. It involves all aspects of managing data throughout its lifecycle, from creation to deletion or archiving. Essentially, it's about making sure data is accessible, reliable, and used effectively to support operations and decision-making.
Data management becomes really difficult to achieve in a scenario where the research data is spread across multiple organisations, is multi-omics (genomics, transcriptomics, proteomics, and metabolomics) in nature, and is being published through different journals. To add more complexity to this, there are different versions/stages of the data files (raw, processed, summarised) throughout the data lifecycle, and ingesting the data into the essential workflows becomes all the more complex.  
REsearch Data Management and ANalysis Environment (REDMANE) is a data management and analysis platform that was introduced to resolve these complex issues.
REDMANE resolves these issues by having the following features:
1. Lightweight and flexible ecosystem
2. Doesn't need organisational buy-in
3. Cheaper to run than a full cloud solution
4. Easily handles new data types
5. Focused on importing information quickly and easily
6. Single Sign On
7. Can handle cross-organisation data easily
REDMANE supports different types of datasets, for example, the Whole Genome Sequencing (WGS), Single Cell RNAseq, imaging dataset, and so on. 
I this project, I narrowed down the problem space to creating an MVP to generate synthetic data for the different file types (raw, processed, and summarised) for the WGS dataset and creating a workflow to upload the corresponding metadata to a data storage repository, and uploading the corresponding metadata file to a synthetic data storage portal inspired from the cBioportal.

Important links: 
1. Clinical Informatics Collaborative - {generatervis}: https://github.com/Clinical-Informatics-Collaborative/generatervis
2. Clinical Informatics Collaborative - data_storage_portal: https://github.com/Clinical-Informatics-Collaborative/data_storage_portal


**Presenter Name:** Jyoti Bhogal

**Bio:** Jyoti Bhogal is a trained statistician, community builder, and Research Software Engineering (RSE) advocate with a strong foundation in data and open science. A first-generation STEM graduate, Jyoti’s academic journey—from earning multiple merit-based scholarships to completing a Master’s in Statistics—laid the groundwork for her career in research and software. Her curiosity for open-source tools led her to the R community, and eventually into global RSE movements. 
​​As the Co-Lead of the RSE Asia Association, she has played a pioneering role in amplifying the voices and visibility of RSEs in the Asian region. Over the past four years, Jyoti has led numerous community events, cross-continental collaborations, and research studies, including her 2025 SSI Fellowship. Her work reflects a rare blend of technical expertise and empathetic community engagement, consistently advocating for equitable, inclusive, and collaborative research ecosystems in low- and middle-income countries.

**Author names:** Bhogal, Jyoti

---

## 5-minute Lightning Talk

<a id="laptop-to-hpc-an-underworld-story-of-sustainable-accessible-scientific-software"></a>
**Title:** Laptop to HPC – An 'Underworld' Story of Sustainable, Accessible Scientific Software

**Abstract:** How a well-designed “container” environment can revolutionise software distribution, accessibility, and scalability for scientific software!
In this talk, I will outline how Underworld, a geodynamic modelling framework, has transformed its usability and reach through modern container technologies—supporting workflows that span from personal laptops to high-performance computing (HPC) systems and cloud platforms.
Underworld is a Python-based, open-source framework used for simulating large scale Earth processes such as slab subduction, rifting, mantle convection, and groundwater flow. It supports an international and interdisciplinary user base, including academic researchers, educators, and industry partners and is actively used in both teaching and high-end research.
A core principle of Underworld’s modelling philosophy is that scientific models should be easy to start and easy to scale up in complexity (e.g. resolution). We advocate that every model should begin its life on a laptop—with robust reproducibility—and scale seamlessly to cloud or HPC resources. To this end, we have adopted container technologies (including Singularity, Docker, and Binder) to manage software environments, reduce onboarding time, and enable reproducibility across platforms.
This talk will highlight our strategy in using containers to:
* Lower technical barriers for new users and educators.
* Support reproducible science in line with FAIR principles.
* Enable workflows across laptops, cloud platforms (like BinderHub), and national HPC facilities.
* Encourage community contributions and domain-crossing collaborations (GitHub).


**Presenter Name:** Mr. Julian Giordani

**Bio:** Julian Giordani is a Research Software Engineer at the University of Sydney in the School of Geosciences.
Julian is funded by AuScope, to maintain and develop numerical models used by the Geodynamic modelling community. He has been a long time contributor to Underworld, a Geodynamic framework for modelling lithospheric deformation and mantle convection, using FEM+PIC. He works at the nexus of software engineering, numerical modelling and Geodynamics and loves it.


**Author names:** Giordani, Julian; Moresi, Louis

---

## 5-minute Lightning Talk

<a id="write-all-the-things-the-process-of-collaboratively-writing-papers"></a>
**Title:** Write all the things? The process of collaboratively writing papers

**Abstract:** Over the past few months, I have written two papers with a large amount of authors. The first was the notes from a conference workshop on OSS held at eResearchNZ, which I published on Zenodo. The second was a Ten Simple Rules article which I submitted to PLOS Computational Biology, and prepublished on arxiv.org. In this lightning talk, I'll briefly go over how the process went, what I did to be inclusive, and how you can help others improve your papers by inviting them in, too. I'll also cover some gotyas that hit me and made the process harder than expected. 

**Presenter Name:** Richard Littauer

**Bio:** Richard Littauer is a PhD student in Computer Science at Te Herenga Waka Victoria University of Wellington in Pōneke, Aotearoa New Zealand. His primary focus is understanding ecology and bird populations using computational modeling. His research interests beyond that involve open science, open source, community science platforms, and taxonomy. 

He also was the ED for GNOME, and he runs SustainOSS and CURIOSS, among other things. 

**Author names:** Littauer, Richard

---

## 5-minute Lightning Talk

<a id="connecting-communities-through-accessible-design-web-graphics-in-stem-for-the-blind-and-visually-impaired-individuals"></a>
**Title:** Connecting Communities Through Accessible Design: Web Graphics in STEM for the Blind and Visually Impaired Indivisuals

**Abstract:** 
Globally, 2.2 billion people experience vision impairments, with
a significant number residing in developing countries such as In-
dia. The UN Convention on the Rights of Persons with Disabilities
mandates equal access to education for all individuals with dis-
abilities. Yet, insufficient support and limited resources impede
their progress. This lack of educational opportunities marginal-
izes these individuals, depriving them of chances to realize their
potential. Such exclusion perpetuates unemployment, wasting
valuable skills that society urgently needs.

Visual content is dominant in daily lives of sighted individuals,
but it poses major obstacles for blind and visually impaired (BVI)
individuals. Diagrams and graphics, though rich in detail, often
lack alt text, and captions alone frequently fail to convey the full
essence of the content. This issue is particularly pronounced in
STEM fields, where accuracy and precision are paramount, and
such visual information is often rendered inaccessible, thereby
excluding BVI students from full participation. This inaccessibility
directly discourages BVI students from pursuing STEM careers.



**Presenter Name:** Sanchit Ghule

**Bio:** At the age of 14, Sanchit was diagnosed with a rare eye dis-
ease called Retinitis Pigmentosa, which left him legally blind but
with some peripheral vision. Sanchit was always very passionate
about science and mathematics, after his vision loss, his school
denied him taking STEM-based courses, believing that the blind
cannot do STEM. In spite of that, his parents taken his respon-
sibility and decided to help him in his studies, his father and sis-
ter were reading and recording his books and also making sure
that he understands visual diagrams. With his exceptional in-
telligence and diligence, Sanchit excelled in his STEM education.
Further he went onto brave his way through and complete his
B.Tech in Materials Engineering at IITM.
Sanchit is now pursuing a unique MS through the entrepreneur-
ship program at IITM. He works with Prof. Volker Sorge (Univer-
sity of Birmingham) and Prof. Tiju Thomas (Materials, IITM) on
making next generation, audio-tactile graphics available on large


**Author names:** Ghule, Sanchit; Sorge, Volker ; Thomas, Tiju 

---

## 5-minute Lightning Talk

<a id="ease-of-use-maturity-model-for-research-software-in-the-life-sciences"></a>
**Title:** Ease-of-Use Maturity Model for Research Software in the Life Sciences 

**Abstract:** One of the challenges of advocating for research software and Research Software Engineers (RSEs) is the diversity of the stakeholders. This means there is no common language for stakeholders, particularly funders, to communicate in a concrete way and to explain why this is important to the wider research community. 

I have created this Ease-of Use Maturity Model for Research Software as a starting point to introduce concepts of how research software maturity and funding are intertwined, and to provide a common language to use to negotiate with and educate diverse stakeholders. 

This model provides 6 levels of maturity – Inaccessible, Single user, Exclusive, Limited, Global, Fully Accessible - with a description of what each level means in practical terms. 

Within the discipline of bioinformatics within the Life Sciences, there are many examples of both mature and maturing research software. It is for this reason that I have used bioinformatics examples to demonstrate how this Ease-of-Use maturity model could be applied to concrete situations. 

I have also provided examples of the three types of research software – research software algorithms, research workflows, and research systems – and how each type fits into this model. 

Finally, it identifies Research Systems as an exception and attempts to resolve this by redefining the terms in the maturity model. 

**Presenter Name:** Rowland Mosbergen

**Bio:** Rowland has 25 years of experience as a generalist in highly complex environments in the not-for-profit, private, and research sectors and has been a Research Software Engineer since 2010.
 
Over his career he has delivered over $230 million of value in business improvements, recruited 4 multi-disciplinary teams and established over 80 intern teams, and has a strong sales and marketing background. 
 
Rowland founded Practical Diversity and Inclusion, a website that extends best practice in Diversity, Equity, and Inclusion (DEI). He has underpinned DEI in team building, international recruitment, establishment of governance processes, student internship programs, panels and conferences, keynotes, and community fundraising. 

**Author names:** Mosbergen, Rowland

---

## 10-minute Demo/Showcase

<a id="rust-for-scientific-computing-its-good"></a>
**Title:** Rust for Scientific Computing - It's Good!

**Abstract:** The Rust programming language has rapidly become one of the most popular and well-loved languages for system programming, due to its focus on performant memory and thread-safety programming, sophisticated toolchains, and commitment to fostering an inclusive and diverse developer community. It has seen widespread adoption in applications ranging from web browsers to hardware device drivers and operating system kernels.

But despite its performance and safety benefits, Rust has seen comparatively little adoption in the research computing space. I believe this is a missed opportunity.

This talk will provide a brief overview of the Rust programming language, with a focus on technical and community aspects that are well-suited to the unique challenges of research computing. I will also discuss some of the issues that have blocked more widespread adoption in scientific computing, and finish with some success stories of projects that have successfully used Rust to do cool science.

**Presenter Name:** Dr Emily Kahl

**Bio:** Emily is a research software engineer at the Pawsey Supercomputing Research Centre in Australlia. She develops and maintains software for molecular simulation, with a specific focus on GPU-accelerated computing and machine learning methods in quantum chemistry. She has extensive experience developing and supporting software for computational chemistry and molecular modeling and has contributed to multiple open-source molecular dynamics projects.
Emily is also an advocate for open-source software in computational science, and the code she has developed for atomic and molecular simulation has seen widespread use by Australian and international researchers. Prior to joining Pawsey, Emily completed her PhD in physics at the University of New South Wales and worked as a research software engineer at the University of Queensland.

**Author names:** Kahl, Emily

---

## 10-minute Demo/Showcase

<a id="through-the-looking-glass-generating-shared-understanding-using-examples"></a>
**Title:** Through the Looking Glass - generating shared understanding using examples

**Abstract:** A lot of software projects stumble in their very first steps. A team is assembled, a plan is laid out and much furious activity ensues. But no one can figure out exactly what it is that they should be building. There’s a lot of conversations and a lot of cycles are wasted trying to figure out exactly what the subject matter experts want when they use certain terms.
 
Eventually the developers commit code to the repo and the first software drops and everyone is left with a vague feeling of disappointment when it doesn’t hit the mark. If the team is lucky, they have enough time to course correct and come up with a usable software product, albeit lacking some features.  

But it doesn’t have to be this way. Agile software development has matured and a number of disciplined techniques have evolved to sharpen the fuzzy front-end of software development. These tools enable software engineers to turn project goals into software features and to use examples to translate domain expert language into specific rules that govern software behaviour.  



**Presenter Name:** Nick Jenkins

**Bio:** Nick has been a software professional for more than 30 years. Starting in testing and moving on to running his own cloud software consultancy he now works at the ARDC as their Software Specialist. He helps ARDC partners and research institutions to build better digital research infrastructure through software and promotes the profile of research software engineering in Australia.

**Author names:** Jenkins, Nick

---

## 10-minute Demo/Showcase

<a id="creating-an-open-source-data-processing-pipeline-for-archival-research-lessons-learned-from-the-case-study-on-g-v-vernadskys-correspondence"></a>
**Title:** Creating an open-source data processing pipeline for archival research – Lessons learned from the case study on G. V. Vernadsky’s correspondence

**Abstract:** In the current presentation, I aim to showcase my technical and methodological approach to the analysis of the reception and transformation of Eurasianism during the Cold War. Specifically, I will point my attention to G. V. Vernadsky (1887–1973) – the former member of the interwar Eurasianist movement who emigrated to the U.S. in the late 1920s and became one of the most established scholars in the field of U.S. Slavic Studies. The research is based on the implementation of open-source digital tools for advanced data processing and analysis of unpublished archival documents from the Slavonic Library in Prague, the Anna Akhmatova Museum in Saint Petersburg, and the Bakhmeteff Archive in New York. The main aim is to present the benefits and shortcomings of the unified technical and methodological workflow for data analysis which includes HTR/OCR processing of archival scans (Tesseract), metadata categorization (Arkindex, Zotero), research logs (Logseq) and graph visualizations of G. V. Vernadsky’s professional network and intellectual development after WWII (NodeGoat, Gephi).

**Presenter Name:** Michal Racyn

**Bio:** Michal Racyn is a postdoc researcher at Masaryk University focused on the development and transformation of Eurasianism during the Cold War. His current research is based on the advanced digital analysis of archival documents located in Prague (Slavonic Library), Saint Petersburg (Anna Akhmatova Museum), and New York (Bakhmeteff Archive). His first monograph and up-to-date articles deal with the reception of Eurasianist historiographic and historiosophic concepts in the Soviet academia and Russian nationalist milieu between the late 1950s and early 1990s.

**Author names:** Racyn, Michal

---

## 10-minute Demo/Showcase

<a id="streamlining-genomics-workflows-navigating-technology-and-skill-limitations-in-collaborative-development"></a>
**Title:** Streamlining Genomics Workflows: Navigating Technology and Skill Limitations in Collaborative Development

**Abstract:** As University of Melbourne students working on the Genomics Metadata Multiplexing (GMM) project at Walter and Eliza Hall Institute, we'd like to share our experience navigating the challenges of improving research software workflows while working within real-world constraints.

We inherited a collection of scripts and prototypes from previous cohorts, each tackling different aspects of FACS file processing for genomics research. Our task was to consolidate these efforts into something more usable for researchers, but we quickly discovered the challenges of working with limited technical resources, varying skill levels across team members, and tight project timelines.

This presentation will walk through our approach to consolidating Flask and R-based solutions into a single R Shiny application while managing these constraints. We'll discuss how technology limitations shaped our decisions, how we adapted to different team members' programming backgrounds, and the creative solutions we found when ideal approaches weren't feasible.

Key insights include: working within deployment constraints rather than fighting them, leveraging team members' diverse strengths instead of expecting uniform expertise, and building incrementally when resources are limited. We'll demonstrate our current workflow automation tool and share practical lessons about making progress despite imperfect conditions.

This presentation is aimed at fellow students, early-career RSEs, and anyone working on research software projects with limited resources.

**Presenter Name:** Sijia Zeng, Jude Thaddeau Data, Sunchuangyu Huang

**Bio:** University of Melbourne Graduate Students working on the Genomics Metadata Multiplexing (GMM) project at the Walter and Eliza Hall Institute of Medical Research. As part of a collaborative student intake program, we've been developing solutions to automate and streamline FACS file processing workflows. Our work focuses on migrating legacy code, improving user interfaces, and building robust testing frameworks while working within real-world technical constraints and user requirements.

**Author names:** Huang, Sunchuangyu Huang; Data, Jude; Zeng, Sijia

---

## 10-minute Demo/Showcase

<a id="new-tool-that-improves-research-reproducibility-by-integrating-high-performance-computing-with-continuous-integration"></a>
**Title:** New tool that improves research reproducibility by integrating High Performance Computing with Continuous Integration 

**Abstract:** Continuous Integration (CI) is essential in modern software development, enabling frequent code integration, automated testing, and rapid feedback. For research, CI enhances reproducibility and efficiency, but High Performance Computing (HPC) environments pose unique challenges, such as hardware diversity, job scheduling, resource management requirements, and strict administrative policies.

We present ‘hpci’, a software tool developed to integrate mainstream CI platforms with High Performance Computing (HPC) environments. We demonstrate how this software, in conjunction with data version control (DVC) and other tools, enables researchers to validate reproducibility. Changes committed to workflows trigger HPC jobs to run the amended workflow on test data, with DVC verifying that identical results are produced. Jobs are monitored by ‘hpci’, so that test failures are easily visible in CI logs.

Catching issues early in development accelerates debugging and optimisation, while minimising the risk of failures in large-scale production jobs. Automatic validation gives researchers confidence to adapt and extend  workflows, which  particularly benefits  collaboration and migration between different HPC systems.

As computational research continues to increase in scale, integrating CI with HPC is critical for maintaining reproducibility across platforms and labs, empowering researchers to focus on discoveries rather than debugging.

**Presenter Name:** Ignatius Menzies

**Bio:** Ignatius Menzies is a software engineer at the Garvan Institute of Medical Research. Prior to this he has worked as Reproducible Research Lead at a data science agency; as a software engineer at Datacom, and as a data scientist at the New Zealand Ministry for the Environment. He has a PhD in Ecology and Evolution from Victoria University of Wellington (NZ)

**Author names:** Menzies, Ignatius

---

## 15-minute Presentation

<a id="pipelines-and-people-reproducible-research-with-nextflow-and-the-nf-core-community"></a>
**Title:** Pipelines and people: Reproducible research with Nextflow and the nf-core community

**Abstract:** Reproducibility is a cornerstone of credible science, but as research grows in complexity and scale, ensuring consistent and transparent workflows across teams and infrastructures has become increasingly challenging. This presentation explores how Nextflow, an open-source workflow manager, and the nf-core community are advancing reproducible, portable, and sustainable research software across disciplines.

Originally developed for the life sciences, Nextflow has matured into a versatile platform that enables researchers to develop and share workflows that run seamlessly across local machines, HPC systems, and cloud environments. At the heart of its success is the nf-core community, a global, collaborative network of over 10,000 contributors who maintain high-quality, reusable workflows through open development, shared standards, and regular community events.
This talk will highlight how these tools and communities reflect the FAIR principles (Findable, Accessible, Interoperable, and Reusable), promote long-term software sustainability, and encourage cross-disciplinary knowledge sharing. Rather than offering a one-size-fits-all solution, we will offer practical reflections on how these practices have supported reproducibility and collaboration in diverse research settings.

**Presenter Name:** Christopher Hakkaart

**Bio:** Christopher is an Education Engineer at Seqera, where he supports researchers in adopting reproducible and scalable data analysis practices. With a background in bioinformatics and a passion for open science, he focuses on creating educational resources that empower the global scientific community to use tools like Nextflow and nf-core effectively.

**Author names:** Hakkaart, Christopher

---

## 15-minute Presentation

<a id="bridging-governance-access-and-technology-issues-in-health-a-sociotechnical-view-from-the-philippines"></a>
**Title:** Bridging Governance, Access, and Technology Issues in Health: A Sociotechnical View from the Philippines 

**Abstract:** 
Adopting a socio-technical approach to information, communication and technology adoption,  the evolving research agenda for bridging governance, access and technology issues in health interrogates critical intersections in building innovative solutions for enhancing health systems  in the Philippines. It aims to contribute to a broader research theme of the Ateneo de Manila University, Philippines on “Filipino Cultures, Communities and Technologies: Forging Pathways and Partnerships of Change.” Pursuing a Digital Public Good (DPG) model in technology dissemination, it  provides a venue for  researchers and other stakeholders in the health, development and academic  sectors to discuss key challenges, share best practices, and identify strategies to improve healthcare delivery and accessibility through effective governance and technology integration. The research agenda cuts across three clusters of themes namely:  transformative health policies and programs,  bridging differential vulnerabilities to address inequity issues and capacity building for health systems strengthening


**Presenter Name:** Dennis B. Batangan, MD, MSc (Heidelberg)

**Bio:** Dr. Batangan, a distinguished  senior faculty member and research scientist at Ateneo de Manila University. He holds positions within the School of Social Sciences, School of Government, Ricardo Leong Institute for Global and Area Studies and Institute of Philippine Culture. With degrees in psychology and medicine from the University of the Philippines, he furthered his studies with a post-graduate course in Community Health for Developing Countries at the University of Heidelberg, Germany. Dr. Batangan's career is marked by transformative contributions to community and public health. He co-founded the Community Medicine Development Foundation, Inc (COMMED), pioneering social innovations. His research on the eHATID Local Government Unit (LGU) system , Smarter and Integrated Local Health Information Systems (SMILHIS), Traditional Medicine as Incipient Technologies and the 'eTSI NOVuS' project showcased his prowess, receiving prestigious nominations and medals for their impact. 

**Author names:** Batangan, Dennis

---

## 15-minute Presentation

<a id="federated-learning-why-what-how-where-to"></a>
**Title:** Federated Learning - Why, what, how, where to.

**Abstract:** As data privacy regulations tighten and datasets grow increasingly siloed across institutions, Federated Learning (FL) offers a transformative approach to collaborative machine learning in the research domain. This talk introduces the core principles of Federated Learning—how it enables model training across decentralised data sources without moving the data itself—and explores its relevance to research environments where data sensitivity, ownership, and locality are paramount.
 
We will outline the main types of FL, including horizontal, vertical, and federated transfer learning, and discuss their applicability to real-world research scenarios. Drawing from our own experience, we’ll share insights into evaluating and selecting FL frameworks, the practical challenges of setting up federated infrastructure, and lessons learned from early implementations.
 
Finally, we’ll look ahead to where the field is going: the growing role of privacy-preserving technologies like differential privacy and secure multiparty computation, the need for standardisation, and the potential for FL to unlock new forms of cross-institutional collaboration in science and academia.
 
This session will provide a practical and forward-looking perspective on how Federated Learning can reshape data-driven research.

**Presenter Name:** Peter Marendy

**Bio:** Peter is currently employed as Head of Data and Software Solutions at QCIF Ltd, which provides eResearch infrastructure and services for Australian research institutions and contributes to the National Research Infrastructure.
Peter leads a team delivering innovative results for various research programs, with expertise in workflows, special computing, data management, and handling sensitive information.
Prior to his role with QCIF, Peter led the Microsystems research within CSIRO’s Cybernetics research Group.
Peter brings his experience in team/capability management, project management, and customer focused collaboration and relationships.
He also has more than 20 years of software engineering experience across multiple domains, including Digital Agriculture, Energy, Food and Nutritional Sciences, Health, Marine Sensing, Robotics, and Visual Analytics, in research and innovation environments.


**Author names:** Marendy, Peter

---

## 15-minute Presentation

<a id="h5pydantic-an-orm-for-hdf5-files"></a>
**Title:** H5Pydantic, an ORM for HDF5 files

**Abstract:** h5pydantic is a Pydantic based library aimed at making it easier for scientists to organize their HDF5 files, by writing Python models of their experiments. The library is similar to an Object Relational Mapper (ORM), but instead of targeting a relational database, it targets HDF.

The library is inspired by the need of the Australian Synchrotron during the commissioning of ourvnew beamlines under the BRIGHT program. The library is currently under development.

**Presenter Name:** Clinton Roy

**Bio:** Clinton is an Open Source software engineer who has made a career around supporting researchers.

**Author names:** Roy, Clinton

---

## 15-minute Presentation

<a id="towards-scalable-biocuration-workflows-for-biomedical-research-data-management"></a>
**Title:** Towards Scalable Biocuration Workflows for Biomedical Research Data Management

**Abstract:** As biomedical research generates increasingly complex and diverse datasets, biocuration, which is the essential process of annotating and managing data with accurate metadata, remains widely overlooked by researchers. This is often because existing curation tools are fragmented, difficult to use, and disconnected from researchers’ day-to-day workflows. 

Consequently, uptake of biocuration practices remains low, partly because curation efforts often focus on samples and patient data but rarely extend to the files themselves. Metadata for research files is typically designed for IT system administrators rather than researchers, making it difficult for scientists to organise and manage their data effectively. This gap is especially problematic when research data is scattered across multiple platforms or institutions. There is a critical need to develop intuitive, researcher-friendly biocuration solutions that simplify file-level metadata management, reduce technical barriers, and integrate smoothly into researchers’ existing workflows making curation a natural and valued part of the research lifecycle.

To address these challenges, we propose a modular and extensible biocuration approach that integrates seamlessly into researchers’ workflows, enabling scalable, efficient, and community-aligned data stewardship. Key components include:
1. Flexible annotation workflows: Allow researchers to begin with simple annotations and gradually add more detailed, structured information as needed, making the process less overwhelming and more adaptable to their workflow.
2. Schema harmonisation and validation: Ensuring consistent, interoperable metadata compliant with community standards.
3. User-centric design: Intuitive interfaces tailored to reduce technical barriers and encourage adoption by domain experts.
4. Collaborative tools: Facilitating coordination between curators, researchers, and data engineers to support multi-disciplinary engagement.

By embedding biocuration into everyday research practices, this approach fosters long-term sustainability of data management, aligns with FAIR principles, and enhances the reproducibility and transparency of biomedical research. This work highlights how scalable biocuration can empower researchers to maximise the impact and reuse of their data across the biomedical community.

**Presenter Name:** Sakshi Patel

**Bio:** A biomedical researcher and data curator with a background in biotechnology and a growing focus on bioinformatics and data management. I currently work at the intersection of clinical research and data infrastructure, with experience in public data harmonisation, and quality control in large-scale biomedical projects. My recent work focuses on streamlining biocuration workflows to make them more accessible, sustainable, and aligned with FAIR principles. I am particularly interested in bridging the gap between domain scientists and technical teams by designing intuitive, researcher-friendly tools and processes.

Through this presentation, I hope to contribute to community-driven improvements in research software and data management practices. My learning path is focused on developing scalable infrastructure and collaborative frameworks for long-term data sustainability in healthcare research.

**Author names:** Patel, Sakshi

---

## 15-minute Presentation

<a id="building-capability-in-rse-for-the-humanities-and-social-sciences-hass"></a>
**Title:** Building Capability in RSE for the Humanities and Social Sciences (HASS)

**Abstract:** The Humanities, Arts, Social Sciences (HASS) & Indigenous research community faces a shortage of Research Software Engineering (RSE) expertise, leading to fragmented and inconsistent software development practices. While great progress has been made by individuals in the sector, dissemination of tools and techniques is poor, leading to inconsistent maturity and approaches across disciplines and research efforts. This paper will describe an initiative that aims to resolve that situation through the development of architectural principles, a technology roadmap, and the publication of recommended patterns. The initiative is not only aimed at RSEs, but also researchers in HASS & Indigenous fields who utilise custom developed software based data collection, processing, storage, analysis and/or publishing methods, ‘Researchers-who-code’, and GLAM sector technical managers and staff. The outputs will be developed in consultation with a wide variety of projects to ensure grassroots involvement, and made freely available online. Our goal is to help people involved in digital HASS research produce more innovative, reproducible, secure and sustainable outputs. By presenting our work at RSEAA we hope to elicit input from RSEs from a wide variety of disciplines and start a conversation about how to design, build, and maintain community assets of this kind.

**Presenter Name:** James Smithies, Peter Sefton

**Bio:** James Smithies is Professor of Digital Humanities and Director of the HASS Digital Research Hub at the Australian National University. Peter Sefton is Principal Research Fellow in the School of Languages and Cultures at the University of Queensland.

**Author names:** Smithies, James; Sefton, Peter; Jenkins, Nick 

---

## 15-minute Presentation

<a id="building-emotional-infrastructure-for-oss-communities"></a>
**Title:** Building Emotional Infrastructure for OSS Communities

**Abstract:** Open source sustainability discussions often overlook the emotional infrastructure that underpins healthy communities. This talk explores how psychological safety nets and supportive environments are essential for both contributors and maintainers.
Drawing from her experience as a contributor and mentor, Laura Langdon will examine the parallel emotional challenges faced by both groups. New contributors need scaffolding to overcome impostor syndrome, while maintainers—whose emotional needs are frequently overlooked—require support in building confidence as community leaders.

Langdon will offer practical frameworks for:

	•	Creating psychological safety in contribution processes
	•	Establishing maintainer support networks
	•	Implementing communication structures that acknowledge emotional work
	•	Building resilience into community governance

Attendees will gain insights into how emotional infrastructure strengthens community health and project longevity. As the open source ecosystem matures, our understanding of sustainability needs to embrace the human elements that determine a project's success.

**Presenter Name:** Laura Langdon

**Bio:** Laura Langdon is the Community Manager for the Open Source Program Office (OSPO) network of the University of California. With a focus on the humans in tech communities, Laura is passionate about documentation, diversity and inclusion across all axes, and social responsibility. Working to connect people within the UC open source community to one another and to the greater world of open source, her responsibilities include planning meetups, helping to connect aspiring contributors with projects and vice versa, and creating educational materials about OSS workflows.

Laura has previous experience as a developer advocate and as a math lecturer at CSU East Bay. This breadth of background in both academia and industry provides her with unique insights into making technical concepts accessible and fostering inclusive community growth.

In her free time, Laura enjoys recreational research, knitting, and optimizing all the things.

**Author names:** Langdon, Laura

---

## 15-minute Presentation

<a id="piloting-peer-code-review-in-a-research-consortium-community-of-practice"></a>
**Title:** Piloting peer code review in a research consortium community of practice

**Abstract:** Code for research is more flexible than point-and-click statistical softwares, but can be more error-prone. These errors may be conceptual (e.g., implementing the wrong function for a given task), programmatic (e.g., indexing the wrong column of a data frame), or syntactic (e.g., the incorrect spelling of a statement or function). Although peer review is part of the scientific process, it rarely (though increasingly) involves review of research code. Part of the difficulty with implementing formal peer review of code is the time, expertise, and supportive environment required to successfully execute it. Particularly for more involved analyses, review of code requires significant time to understand the context, questions, data, methods, and aims. It can also be very difficult to identify people with the appropriate skills in both the given code language and the methods to effectively review the code. Lastly, despite peer review itself being a common and integral part of the research process, people are still less prepared to open up their code itself for review and so a constructive, supportive, peer space is necessary. We present a pilot program for peer code review conducted within a research consortium setting, which may represent a useful model to overcoming these challenges. The Australia-Aotearoa Consortium for Epidemic Forecasting & Analytics (ACEFA) aims to support timely and effective responses to epidemic diseases in Australia and New Zealand through real-time data analytics, modelling, and forecasting. One of our main activities this winter is reporting short-term forecasts for daily case counts of several respiratory pathogens, for each Australian state and territory and for New Zealand, to government health committees and stakeholders. We have multiple forecasts from models developed and maintained by one or more research academics in our consortium. In parallel with a review period for the methods in these models, we are also planning to conduct peer code review of models with the following aims in mind:
1. To confirm that each model implements the documented methods;
2. To identify potential improvements in each model's implementation;
3. To share expertise about good coding practices; and
4. To increase exposure to, and familiarity with, code review as a means to support computational research. 
We will conduct pre- and post- evaluation surveys to evaluate how well we address each aim, and to provide evidence for iterative improvements for future rounds of code review. We will present this initiative as a component of our community of practice, and hope to initiate a discussion with participants about its merits and dissemination of the model.

**Presenter Name:** Saras Windecker, Rob Moss

**Bio:** Dr Saras Windecker is a Senior Research Officer at The Kids Research Institute Australia working in infectious disease modelling and software development. Dr Rob Moss is a Senior Research Fellow in the Infectious Disease Dynamics Unit at the Melbourne School of Population and Global Health, The University of Melbourne with a focus on the development and application of high-performance computational modelling methods for predicting and mitigating the burden of seasonal and pandemic influenza. 
Drs Windecker and Moss are both members of the Australia-Aotearoa Consortium for Epidemic Forecasting & Analytics (ACEFA), which aims to support timely and effective responses to epidemic diseases in Australia and New Zealand. They are both actively involved in the open research community and interested in promoting reproducible research practices. 

**Author names:** Windecker, Saras; Moss, Rob

---

## 15-minute Presentation

<a id="developing-australias-first-epidemic-forecasting-hub"></a>
**Title:** Developing Australia’s first epidemic forecasting hub

**Abstract:** Epidemic forecasts are essential to understanding the current burden of illness – for example, of common winter respiratory pathogens – in the community. Forecasts that accommodate inputs from multiple models (e.g. through ensembling) are generally more useful for decision makers as they can simultaneously account for greater uncertainty and provide more weight to the most likely prediction. However, coordinating multiple teams can be a difficult and time-consuming exercise. Epidemic forecasting hubs provide dedicated infrastructure to meet this need. The hubverse is a collection of open-source software and data tools that was first developed to support collaborative modelling for COVID-19 in the USA and is now available on GitHub for others to use.
The Australia-Aotearoa Consortium for Epidemic Forecasting & Analytics (ACEFA) has been developing Australia’s first epidemic forecasting hub to support multi-model forecasting of common winter respiratory illnesses. Our forecasting hub has been built upon existing hubverse infrastructure but required substantial modifications to meet our needs. Additionally, as our consortium is comprised almost entirely of research academics, we have had to accommodate varying levels of expertise in research software engineering (for example, not all members were familiar with version control and some are unable to access GitHub in their workplace). 
In this talk I will give a general overview of the infrastructure underpinning the ACEFA forecast hub, including how we are developing increasing automation of data processing, model validation and ensembling. The hub is currently in active use as we provide weekly reports of short-term forecasts of key respiratory pathogens to stakeholders in Australian states and territories. Ensembled model forecasts aim to predict the daily case counts of influenza, RSV and COVID-19 up to four weeks forward in time and are comprised of individual models that are developed and maintained by different members of the consortium. Due to our data sharing agreements, the forecast hub is currently private and there are additional security considerations around the processing of raw data and sharing of model outputs. However, ACEFA has a longer-term aim to open model contributions up to external members in the community and provide public reporting of respiratory pathogen trends. 


**Presenter Name:** Katharine Senior

**Bio:** Dr Katharine (Kate) Senior is a postdoctoral researcher at The Kids Research Institute Australia. Her research focuses on building models and software for epidemic situational assessment, preparedness and forecasting. She is the Data Lead of the Australia-Aotearoa Consortium for Epidemic Forecasting & Analytics (ACEFA) and during the COVID-19 pandemic worked with a group of researchers to present weekly models and reports of current infection trends to the Australian government. 

**Author names:** Senior, Katharine; Windecker, Saras; Tobin, Ruarai; Moss, Rob; Shearer, Freya

---

## 15-minute Presentation

<a id="from-bench-to-gpu-a-biologists-journey-into-virtualised-cryo-em-data-processing-on-bunya-hpc"></a>
**Title:** From Bench to GPU: A Biologist’s Journey into Virtualised Cryo-EM Data Processing on Bunya HPC

**Abstract:** As structural biology embraces an era of big data and GPU-intensive workflows, traditional data processing methods are no longer keeping pace, at the University of Queensland (UQ) we have managed to solve this issue at scale for our researchers utilising Open OnDemand and clever integration to Bunya HPC. In this presentation, I share a biologist’s perspective on navigating this shift from broken traditional data processing methods, to leading the field as the new gold-standard thanks to an interdisciplinary collaboration with the Research Computing Centre and the structural biology community at UQ. Together, we developed a visual, on-demand virtual desktop platform for the Bunya supercomputer that enables complete Cryo-EM data processing, no command-line skills required.
This new environment integrates key software tools used in structural biology, including CryoSPARC, Relion, ModelAngelo, ChimeraX, Coot, and more, within a single virtual desktop interface. Users can process large datasets, visualize structures, and leverage A100, H100 and L40 GPUs with minimal technical overhead. By removing barriers to HPC access, this platform empowers researchers to focus on discovery, not infrastructure.
I reflect on what made this project successful —clear communication across disciplines, shared vision, and a user-centred design. As compute becomes increasingly specialised, while scientific research demands higher compute, I argue that platforms like this are essential for bridging domain expertise and digital infrastructure, and I offer lessons for institutions seeking to support transdisciplinary science at scale.

**Presenter Name:** Dr. Farrah Blades

**Bio:** Dr Farrah Blades is a structural biologist and post doctoral researcher at the Institute for Molecular Bioscience (IMB), University of Queensland. She specialises in cryo-electron microscopy (Cryo-EM) and is passionate about improving access to high-performance computing (HPC) for scientists. In collaboration with Research Computing Centre (RCC) engineers at UQ, she co-developed onBunya, a virtual desktop platform that enables GPU-powered Cryo-EM processing on UQ’s Bunya supercomputer—removing technical barriers of entry for researchers.

Farrah led efforts to integrate Cryo-EM software into onBunya, streamline data workflows, and train structural biology users across UQ. Her work bridges the gap between experimental biology and computational infrastructure, aiming to reduce barriers of entry and accelerate scientific discovery. She is committed to championing user-friendly HPC solutions, cross-disciplinary collaboration, and open-access tools. 

**Author names:** Blades, Farrah 

---

## 15-minute Presentation

<a id="biometryassist-connecting-statistical-tools-with-agricultural-research"></a>
**Title:** biometryassist: Connecting Statistical Tools with Agricultural Research

**Abstract:** The biometryassist R package is a practical example of how research software can help bridge the gap between statisticians and applied researchers, supporting the growth of sustainable communities of practice. The package was developed by the Biometry Hub at the University of Adelaide.  It was created to address a common problem: helping agronomists and researchers working in Australia's agricultural sector apply sound statistical methods without requiring extensive programming skills.

Too often, statistical software creates a divide between those who understand the methods and those who need to apply them. biometryassist aims to close that gap with user-friendly functions, clear naming conventions, detailed documentation, and simple workflows for both designing and analysing experiments. It brings together tools that were previously scattered across different scripts, packaging them in a consistent and accessible way via CRAN.

biometryassist also empowers a growing Community of Practice, where researchers regularly come together to solve problems and share ideas. Many members first encounter the package in a workshop setting regularly run by the Biometry Hub and then go on to use it in their own work. Some also contribute to community discussions, creating an ongoing cycle of learning and support.

Key community-building features include: functions designed to minimise cognitive load for non-programmers, semi-automated visualisations to help with interpreting results, and alignment with established agricultural research workflows. By reducing technical barriers, the package enables researchers to focus on the science rather than wrestling with software.

This presentation will show how thoughtful software design and community engagement can go hand-in-hand to build capability, promote collaboration, and lift the quality of statistical practice across an entire research sector.

**Presenter Name:** Sam Rogers

**Bio:** Sam Rogers is a Biometrician and Research Software Engineer at the University of Adelaide Biometry Hub where he writes R packages and web apps, especially in support of agricultural research. Sam is a RStudio certified instructor and teaches regular professional development workshops on experimental design and analysis using R. Sam also provides statistical consulting to researchers and students, and is passionate about statistical computing and helping people make the most out of their data.

**Author names:** Rogers, Sam; Conway, Annie; Nielsen, Sharon; Edson, Russell; Gogel, Beverley; Kravchuk, Olena

---

## 15-minute Presentation

<a id="adacs-lessons-learned-on-the-road-to-a-new-model-for-creating-and-maintaining-research-software"></a>
**Title:** ADACS: lessons learned on the road to a new model for creating and maintaining research software 

**Abstract:** Addressing the requirements for transparent, cost effective and high-impact research in this era of big data and cross-disciplinary research will require significant community changes to how research software is created, managed and maintained.  In this talk I will introduce Astronomy Data And Computing Services (ADACS): a highly successful initiative of the Australian astronomy community established to address the need for coordinated national investment in software systems and training.  Established by Astronomy Australia Limited (AAL) via funding from the federal National Collaborative Research Infrastructure Strategy (NCRIS), ADACS has operated since 2017 under the mandate of optimising the return from Australia’s investment in astronomy computing infrastructure. In practice however, it is working to shift the culture and practices around the creation and maintenance of research software; towards a more modern, professional and sustainable model built upon maximising the expertise of cross-functional teams.  I will give a quick account of ADACS and it's activities and discuss some of the lessons learned over the years.

**Presenter Name:** Gregory B. Poole

**Bio:** An astronomer and numerical simulator by training, I conducted cosmological research in a high-performance computing (HPC) environment for 10 years as an Australian postdoctoral researcher before joining Astronomy Data and Computing Services (ADACS) as a senior developer in 2017.  Presently I am the program manager of the Swinburne ADACS node, helping to manage the activities of ~15 research software engineers and software professionals.

**Author names:** Poole, Gregory

---

## 15-minute Presentation

<a id="modernising-io-and-parallelisation-in-the-cable-land-surface-model"></a>
**Title:** Modernising I/O and parallelisation in the CABLE land surface model

**Abstract:** Maintaining legacy software is a challenging task, but for numerical models such as the CABLE land surface model, it is necessary to ensure the software remains relevant and useful for current and future researchers in the climate and terrestrial modelling community. Several performance and software maintenance issues voiced by the CABLE community called for a redesigning of CABLE’s I/O and MPI architecture, which is what we propose. Building on community feedback and internal analysis of the software, we focus on 1) unifying the MPI and serial source code to ease software maintainability, and 2) replacing the MPI architecture from master-worker to parallel I/O for improved performance and scalability. This presentation will introduce the software development approach taken by the team and the challenges it entails. It will then discuss key design decisions taken to ensure the model is easily portable and usable by all researchers, prioritising accessibility in addition to performance and maintainability for future development. 

**Presenter Name:** Sean Bryan

**Bio:** I'm a research software engineer for the land surface modelling team at ACCESS-NRI. I specialise in developing parallelised numerical models for high performance computing applications and am currently a developer for the CABLE land surface model. 

**Author names:** Bryan, Sean

---

## 15-minute Presentation

<a id="bridging-climate-science-and-collaboration-through-software-tools-at-the-global-km-scale-hackathon"></a>
**Title:** Bridging Climate Science and Collaboration Through Software tools at the Global km-Scale Hackathon

**Abstract:** In May 2025, over 60 PhD students and early-career researchers from five Australian universities and international institutions gathered in Canberra for the Global km-Scale Hackathon, a week-long event focused on analysing next-generation, kilometre-scale global simulations organised by the World Climate Research Program. This global initiative was part of a broader international collaboration, with groups working around the world (and the clock!).

This presentation will showcase how the Research Software Engineering team at the ARC Centre of Excellence for the Weather of the 21st Century played an important role in organising the event. Our contributions spanned the technical, educational, and collaborative domains. We managed the transfer ~50 Tb of data from HPC centres in the UK and Germany to NCI’s Gadi supercomputer, a process requiring extensive testing and optimisation. We developed and deployed a shared conda environment tailored to working with simulations stored in the novel healpix grid format, which demanded the use of new tools and workflows unfamiliar to most participants.

In addition to technical infrastructure, we produced extensive documentation to support participants in understanding the simulations, the data format, and the analysis environment. Recognising the importance of collaborative practices, we led training sessions on Git and GitHub to equip participants with the tools and workflows needed for effective teamwork. We also supported project leaders in managing their research workflows on GitHub, including issue tracking, team coordination, and templated repositories.

By connecting researchers, tools, and best practices, this project demonstrated the critical role of RSEs in enabling cutting-cutting-edge research. Our work helped lower barriers to entry, fostered new collaborations, and empowered participants to focus on scientific discovery. This talk reflects on the lessons learned, the challenges, and highlights the importance of RSEs in building bridges between domains, disciplines, and people.

**Presenter Name:** Paola Corrales

**Bio:** Paola has a PhD in Atmospheric Science from the University of Buenos Aires. During her PhD, Paola applied data assimilation techniques to improve the representation of mesoscale convective systems and associated precipitation. In particular, her research focused on data assimilation of conventional observations and radiances from polar and geostationary satellites. She has experience working with Numerical Weather Prediction models and developing software using R and Fortran. She is also part of R-Lades rOpenSci and The Carpentries and is interested in open source, open science and reproducibility. She recently joined the ARC Centre of Excellence for the Weather of the 21st Century as part of the Research Software Engineer Team. 

**Author names:** Corrales, Paola

---

## 15-minute Presentation

<a id="cryo-em-data-at-scale-how-collaborative-models-arose-around-the-world"></a>
**Title:** Cryo-EM Data at Scale: How Collaborative Models Arose Around the World

**Abstract:** Cryo-Electron Microscopy (Cryo-EM) —the electron imaging of biomolecules flash-frozen in their near-native state— is now delivering direct atomic level views of structures that previously could not be resolved. This view provides immediate mechanistic insight, often clarifying biological processes that had long been debated.

But with this mass of atomic level data comes a massive data challenge. Cryo-EM instruments can generate terabytes of imaging data per day, and this data volume cannot be handled in isolation. To separate the molecular wheat from the chaff, skilled instrument scientists are critical to achieving high resolution; biomolecular domain experts triage live data to identify what's worth interpreting; and research computing provides the processing power to reconstruct these large datasets into 3D maps. 

The Free and Open Source Software (FOSS) community has demonstrated several models for open collaboration that thrive in environments where code sharing and reproduction is near-instantaneous. But as the scale of biodata grows, the demands for storage and compute will increasingly necessitate bringing resources and expertise to the data sources — not the other way around.

In this talk, I'll share experiences coordinating across facilities with different approaches and assumptions to meet shared Cryo-EM needs. I'll then turn to highlight some international efforts to address the Cryo-EM data and modelling burden —  including software packaging and distribution models, as well as inter-facility and even inter-university infrastructure sharing approaches, such as the multicountry Nordic CryoNET initiative. 

**Presenter Name:** Keiran Nicholas Rowell

**Bio:** Keiran is a computational scientist, with a strong background and deep enthusiasm for molecules and the fascinating things that they do.

He currently works at the Structural Biology Facility at UNSW, where he runs calculations using state-of-the-art deep learning programs. His role involves analysing computational models for biosciences researchers, managing a small compute team to optimise workflows, and negotiating with local and national research compute to provide fit-for-purpose resourcing.

Keiran is most driven by the exquisite mechanistic insight offered by atomic-level modelling and data reconstruction. He ardently believes these tools should be made accessible to the domain experts who pioneer meaningful scientific discovery.

**Author names:** Rowell, Keiran

---

## 15-minute Presentation

<a id="no-user-left-behind-how-to-ensure-your-research-software-is-accessible-and-inclusive"></a>
**Title:** No User Left Behind

**Abstract:** The hardest part of building software isn’t the programming; it’s making sure you’re building the right thing for your users. For research software this gets even trickier due to complex research goals and shifting requirements. UX research and accessibility practices have been tackling these problems for decades but most research teams don’t have a dedicated UX designer, let alone a budget or formal training. Fortunately there are simple, practical UX and accessibility methods anyone can use, even in small, inexperienced teams with limited resources. I’ve been applying these methods to research software development for five years and have seen firsthand how much difference they can make. I’ve used UX design to improve web applications, APIs, Python packages, documentation, and tutorials. With a little effort you can add automated accessibility checks, use simple design heuristics, and run quick user interviews to design and build research software that works better for everyone. In this talk, I will share practical tips, real-world stories, and easy ways to get started. You will leave with ideas you can use right away to make your software more accessible and user-friendly, no matter your team size or budget. By making these changes we can connect with a wider community and make our research software more impactful.

**Presenter Name:** Asher Leslie

**Bio:** Asher Leslie is a Software Engineer and UX Designer at Astronomy Data and Computing Services (ADACS), where he helps the Australian astronomical community turn big ideas into usable research tools. With over a decade of experience developing research software, Asher has designed and built everything from psychology platforms to astrophysics web applications. As a certified UX Designer (Nielsen Norman Group), he leads the UX charge at ADACS, championing user-centred and accessible design. Asher is passionate about asking the tough questions, talking to real users, and making sure the right thing gets built.

**Author names:** Leslie, Asher

---

## 15-minute Presentation

<a id="metavaluation-a-participatory-framework-for-recognising-rewarding-and-coordinating-what-matters"></a>
**Title:** Metavaluation: A Participatory Framework for Recognising, Rewarding, and Coordinating What Matters

**Abstract:** This presentation introduces Metavaluation, a participatory framework for assessing the relative value of diverse contributions—including ideas, activities, and resources—within any community. Developed to support the Open Science movement, Metavaluation generates transparent, multidimensional value metrics that empower communities to recognise what matters, reward meaningful participation, and coordinate action and resources toward their shared goals.

The key innovation of Metavaluation is its treatment of peer evaluations as valuable contributions in their own right—anchoring all other valuations to these as a ‘base unit’ of value. This creates a dynamic feedback loop that rewards participation while generating interoperable valuations for any given set of contributions. By closing the loop between evaluation, collaboration, and decision-making, Metavaluation lays the groundwork for scalable, inclusive, and transparent research ecosystems.

We’ll share insights from real-world prototypes spanning science, technology, and the arts, highlighting the framework’s potential to support collaboration across diverse sectors and use cases. We’ll introduce an open-source platform developed by Open Heart + Mind (OHM)—a nonprofit citizen science community—and present data showing how diverse projects can be weighted toward a common mission, empowering positive-sum contributors and enabling global coordination. 

Finally, we’ll present a new dataset created the previous day during a live workshop at RSAA25, where attendees used Metavaluation to nominate and assess contributions to the conference itself. We’ll share learnings from this experiment and explore its relevance to research software communities. To close, we’ll invite all participants to continue the process—nominating overlooked contributions and evaluating their quality—contributing to a living dataset that can inform ongoing reflection, planning, and coordination within RSAA and beyond.

**Presenter Name:** Cooper Smout

**Bio:** Dr. Cooper Smout is a designer, neuroscientist, and open science entrepreneur working at the intersection of collective intelligence, participatory governance, and cultural change. With a background in architecture and a PhD in the neuroscience of consciousness, he left academia to found Free Our Knowledge, a collective action platform for open research, and Open Heart + Mind (OHM), a nonprofit organisation developing open-source tools to empower communities. His current work focuses on Metavaluation, a participatory evaluation framework that generates transparent, interoperable value metrics to support fair recognition and reward, decentralised coordination, and collective governance across research and commons-oriented ecosystems.

**Author names:** Smout, Cooper

---

## 15-minute Presentation

<a id="from-phd-to-rse-training-the-next-generation-of-research-software-engineers"></a>
**Title:** From PhD to RSE: Training the Next Generation of Research Software Engineers

**Abstract:** In 2024, Australia’s Climate Simulator (ACCESS-NRI) launched the trial phase of a PhD internship program. The program enables PhD students to join the ACCESS-NRI team for a few months and get first-hand experience of what it means to be a Research Software Engineer (RSE) in climate modelling. Interns are offered the chance to learn a range of skills, from developing scientific software collaboratively to understanding the technical foundations of climate models. Within this trial phase, which was open to current PhD students at the Australian National University, we have hosted four interns for 3-4 months each. In this presentation, we will share our experience designing and implementing the program, highlight key learnings and outcomes from the trial phase, and discuss our vision for the full program moving forward. Based on feedback from the trial phase, we plan to extend eligibility to include PhD students from other Australian universities when the full program launches in 2026. 

**Presenter Name:** Paige E. Martin

**Bio:** Paige leads the User Training Team at Australia’s Climate Simulator (ACCESS-NRI). She enjoys supporting communities around open-source, scientific tooling. Previously, Paige worked at NASA Headquarters as a Support Scientist in the Office of the Chief Science Data Officer. 

Paige is involved in international, open science-related communities: she is a steering committee member of Pangeo (https://pangeo.io/)– a community for big data geoscience – and OSSci (https://www.opensource.science/) – a community at the intersection of science and open-source software. She has also led the Python computing portion of a West African oceanography summer school (https://coessing.org) for many years. 

Paige has a PhD in Physical Oceanography from the University of Michigan, and did a postdoc in Climate Data Science at Columbia University. 

Outside of work, Paige enjoys handstands, doing partner acrobatics and aerial arts, performing in musical theater, birding, and spending time with family.

**Author names:** Martin, Paige; Druken, Kelsey; Nettelbeck, Heidi

---

## 15-minute Presentation

<a id="redmane-a-lightweight-ecosystem-for-research-data-management-across-organisations-and-diverse-data-types"></a>
**Title:**    REDMANE: A Lightweight Ecosystem for Research Data Management Across Organisations and Diverse Data Types

**Abstract:** Managing research data in multi-organisational, multi-omics environments is increasingly complex yet most existing systems are built for institutions, not researchers. REDMANE (REsearch Data Management & ANalysis Environment) is a lightweight, researcher-focused ecosystem that addresses this critical gap. 

Designed with input from over 40 interns and research staff across clinical, molecular, and data science disciplines, REDMANE replicates the usability of modern library systems for research data. It will combine a flexible data registry with ingestion tools that deliver immediate value to researchers by simplifying curation, improving discoverability, and enabling long-term data retrieval across institutions. 

Crucially, REDMANE highlights the growing need for international standards to support interoperability between these data portals. To unlock the full potential of federated research ecosystems, we must co-develop shared frameworks for authentication and authorisation, mapping unique identifiers between ssytems and making it easier to maintain and develop ecosystems that are fit-for-purpose. REDMANE is built with this future in mind, enabling researchers to plug into a broader, evolving network of interoperable tools and services. 

Unlike platform-centric tools, REDMANE is domain-agnostic and scalable—capable of supporting legacy and incoming datasets in projects in the biomedical space. Its modular architecture supports diverse data portals (e.g., Omero, cBioPortal), enabling researchers to keep large datasets locally while cataloguing and accessing them via a shared metadata layer. 

This architecture should also support other domains including Digital Humanities Arts and Social Sciences. 

By aligning technical capability with real researcher needs, REDMANE demonstrates that uptake, not just delivery, is the key to sustainable RDM. This talk will present REDMANE’s design, use cases, and early implementation feedback, and invite collaboration to grow its open-source, community-driven future. 

**Presenter Name:** Rowland Mosbergen

**Bio:** Rowland has 25 years of experience as a generalist in highly complex environments in the not-for-profit, private, and research sectors and has been a Research Software Engineer since 2010.

**Author names:** Mosbergen, Rowland

---

## 15-minute Presentation

<a id="ai-assisted-humanities-researcher-workbenches"></a>
**Title:** AI-assisted Humanities Researcher Workbenches

**Abstract:** The significance of generative AI for humanities research methods is poorly understood, and greatly underestimated—generally limited to anecdotes about where it makes mistakes and how students are using it to cheat.
The affordances are quite astonishing.  Where AI can generate near perfect Sanskrit, translate and analyse grammar expertly then research practice has changed radically.  Where AI acts as a master’s level assistant able to instantly research, collate, analyse, and present, then then the practice of a digital humanist has changed radically.  
The methodological challenge is what to ask, how to ask it, and how to validate responses.  As humanities researchers, we are ground truth.  We need to engage with generative AI is as active collaborators rather than passive consumers—building workflows that accept or reject outputs, embedding emendations back into model training to align with scholarly standards.
This presentation will explore how generative AI is being integrated across a range of humanities research workbenches we support:
-Glycerine, a IIIF annotation workbench: has integrated an open-source Image AI and IIIF annotation pipeline, supporting iterative, scalable workflows for training models in image segmentation, captioning, and semantic tagging.
-TLCMap, a workbench for mapping history and culture: has implemented an open-source mapping pipeline to extract and geolocate Australian place names from large texts.  Researchers can review, emend, and validate results.
-Omeka S, a graph-based content management system: we are designing modules that embed writing, translation, annotation, and visualisation tasks—powered by generative AI—directly into researcher workflows.


**Presenter Name:** Dr Ian McCrabb

**Bio:** Ian McCrabb is the founder and managing director of Systemik (systemiksolutions.com), a Sydney based IT consulting group focused on open-source digital humanities platforms and research sites.  Systemik is an innovative Consulting Group and Digital Humanities Lab.  We design, develop, implement and support research solutions for humanities projects: open-source platforms, infrastructure integration, APIs, and website content management.  Ian completed his MA in Sanskrit and Buddhist Studies at the University of Sydney in 2010.  His 2021 PhD dissertation 'Buddha Bodies and the Benefits of Relic Establishment: Insights from a Digital Framework for the Analysis of Formulaic Sequences in Gāndhārī Relic Inscriptions' continued his focus on methodologies for the analysis of donative inscriptions and characterization of the ritual practices and religious significance of relic establishment in Gandhāra.

**Author names:** MCCRABB, Ian

---

## 15-minute Presentation

<a id="aurins-internal-developer-platform"></a>
**Title:** AURIN's Internal Developer Platform

**Abstract:** The Australian Urban Research Infrastructure Network (AURIN) is a national leader in delivering digital infrastructure to support advanced urban research. As AURIN transitions toward a next generation framework, we are modernizing our internal and external systems. In this presentation, we introduce AURIN's Internal Developer Platform (IDP), a Kubernetes based solution designed to streamline research application deployment and development on the NECTAR research cloud. Operational for over two years, the IDP provides a robust, scalable, and user friendly environment tailored to the needs of researchers and developers working with data intensive applications. We will highlight key features that empower users to efficiently manage infrastructure, automate workflows, and deploy reproducible environments with minimal overhead. By sharing our experience building and running the platform, we aim to demonstrate how an IDP can enhance research productivity and cloud resource utilisation in a national research infrastructure context.

**Presenter Name:** Muhammad Umer Altaf

**Bio:** Muhammad Umer Altaf is a Principal Software Engineer and Infrastructure Lead at AURIN, where he leads the design of scalable, resilient platforms for urban research. With over a decade of experience, Umer has worked with numerous Australian organizations across research, academia, and defence. He is deeply passionate about distributed systems and thrives on building robust, cloud-native architectures that support high-performance data workflows. His work focuses on enabling open, interoperable platforms that power data-driven discovery and innovation at scale.

**Author names:** Altaf, Muhammad Umer

---

## 15-minute Presentation

<a id="highly-reproducible-r-environments-with-nix"></a>
**Title:** Highly reproducible R environments with Nix

**Abstract:** Scientific studies, particularly those in biology, require long
computational chains to process primary data and extract findings.
These experiments and subsequent processing steps require reproducibility
to have confidence the findings are generalisable to the real world.
As the complexity of the computational processing increases, so too does
the difficulty of ensuring reproducibility of our software environments.

The Nix project aims to provide highly reproducible computational
environments and software through declarative and side-effect
free specifications of build processes.  Through these declarative
specifications, a large number of software projects (>106k) have available
to Nix users as packages (nixpkgs).  I will explain this fundamental
abstraction and show how it results in a high degree of reproducibility
and compositionality between the build products.  In particular, I will
show how support in nixpkgs for R – a language commonly used for data
science – includes all packages published on CRAN and BioConductor.
This allows the construction of highly reproducible R environments that
are easily deployable without the use of containerisation technologies
such as Docker and apptainer.


**Presenter Name:** Justin Bedo

**Bio:** Justin Bedő is a researcher at the Walter and Eliza Hall Institute
of Medical research and a long-time contributor to the Nix open-source
project.  He graduated with a Bachelor of Software Engineering (2005)
and PhD in Engineering (2009) from the Australian National University.
He has extensive experience across both academia and industrial research,
having previously worked at NICTA, l'laboratoire IBISC in Paris, and
IBM Research Australia.  His research interests span Machine Learning,
bioinformatics, privacy, and reproducible research.


**Author names:** Bedo, Justin

---

## 15-minute Presentation

<a id="modernising-urban-research-with-traefik-modular-access-gateway"></a>
**Title:** Modernising Urban Research with Traefik: Modular Access Gateway

**Abstract:** For over 14 years, the Australian Urban Research Infrastructure Network (AURIN) has been a national leader in delivering digital infrastructure to support advanced urban research. As AURIN transitions towards a next-generation framework, the focus is on standardised, interoperable data and analytics delivery methods. AURIN has recently added an ingress layer on top of its existing technology stack to provide secure and efficient access to these leading-edge digital services. This presentation will share practical insights from applying our selected implementation, Traefik, in real-world scenarios, including access to internal services such as GeoServer (WFS) and integration with external APIs.

Traefik, an open-source reverse proxy and ingress controller, offers an effective solution for managing traffic to both internal platforms and external APIs. Acting as an access gateway, it improves the overall security posture by isolating backend systems from direct internet exposure. Its modular architecture, based on routers, middleware, and services, enables flexible traffic control, authentication, and observability. It supports forward authentication with identity providers such as Keycloak and the Australian Access Federation (AAF), enabling secure, federated single sign-on across institutions. Its declarative YAML configuration and dynamic service discovery – natively compatible with Docker and Kubernetes – significantly reduce operational complexity compared to traditional tools like NGINX.

**Presenter Name:** German Eduardo Gonzalez Gonzalez

**Bio:** German González is a data scientist at the Australian Urban Research Infrastructure Network (AURIN). He holds degrees in History and Economics, as well as master’s degrees in economics and data science. Extensive knowledge in geospatial analysis, econometrics, time series, research, and teaching. He has eight years of experience in consultancy and has participated in several projects supporting researchers in Australia. He has been collaborating with different universities in Australia in the Integrated Research Infrastructure for Social Science (IRISS) project. Likewise, he was a research associate at UNSW Sydney and a research assistant at the Centre of Studies of Economic Development (Colombia).

**Author names:** Gonzalez Gonzalez, German

---

## 15-minute Presentation

<a id="the-big-switch-aurins-pivot-from-portal-to-platform"></a>
**Title:** The Big Switch: AURIN’s Pivot From Portal

**Abstract:** As climatic, demographic, and economic drivers converge to challenge the intimate fabric of our cities and regional centres, the Australian Urban Research Infrastructure Network (AURIN) has a key role to play in providing modern digital research infrastructure to support informed evidence-based urban and infrastructure planning and management.
 
In this presentation we reflect on over a decade of accumulated expertise in digital research infrastructure at AURIN and discuss the current work being done to develop next generation digital research infrastructure built upon interoperable and standardised approaches to data and analytics delivery and execution.
 
The AURIN Data Provider (ADP), launched in July 2022, was the first of these new services to be released and is a major component of AURIN’s data-as-a-service platform. We will describe what motivated its creation, the decommissioning of its predecessor the AURIN Portal, its technical implementation, the learnings we have after its first three years of operation, and the role the ADP has in undergirding future urban research platforms.

**Presenter Name:** Dr Loren Bruns Jr, AURIN Head of Engineering

**Bio:** Dr Loren Bruns Jr is the Head of Engineering at the Australian Urban Research Infrastructure Network (AURIN), a facility providing national-scale digital research infrastructure for Australia’s urban research community. He leads a team of research infrastructure specialists that work to provide urban researchers with access to an ecosystem of modular, cloud-first data and analytics services. Prior to joining AURIN, Loren completed a PhD in Astrophysics from the University of Melbourne and spent a decade as a full-stack research software engineer before transitioning to national research infrastructure.

**Author names:** Bruns Jr, Loren

---

## 15-minute Presentation

<a id="converse-lets-talk-about-mental-health"></a>
**Title:** ConveRSE - Let's Talk About Mental Health

**Abstract:** As part of my Software Sustainability Institute (SSI) Fellowship, I’ve been looking for ways to support mental health in the research software community. 1 in 4 adults experience mental health problems each year, and in 2022, Dave Horsfall conducted a survey which showed that a range of issues are common among Research Software Engineers (RSEs). This is hardly surprising, as working as an RSE or Research Technical Professional (RTP) presents a unique set of challenges; we have to deal with context and technology switching, impostor syndrome, limited career opportunities and recognition, on top of software development being notorious for burnout and… well, everything going on in the world right now! If not properly managed, it can be a recipe for mental health disaster, as I know only too well!

In this talk, I will tell the story of how I became a father in lockdown, how it led to burnout and an anxiety attack, and how that experience motivated me to apply for the Fellowship. I will explain why I believe it is essential to continue the conversation around mental health, to create an environment where people can discuss mental health in the workplace, and why it’s better to address issues before they turn into larger problems. I will look at what we can practically do to support mental health among RSEs (and those in similar professions), including some advice, best practices and other things I’ve learned from telling my story and discussing mental health at various events over the last couple of years. Finally, I will introduce ConveRSE - a new online hub for mental health information, projects and resources aimed at RSEs and RTPs - and encourage people to get involved so we can work together to create a better future for ourselves and our colleagues.

**Presenter Name:** Mike Simpson

**Bio:** Dr Mike Simpson is an RSE at Newcastle University in the UK and an active member of the RSE Community, currently serving as Trustee and Vice-President of the UK Society of RSE. He is a 2025 Fellow of the Software Sustainability Institute, hoping to continue the conversation around mental health in our community.

**Author names:** Simpson, Mike

---

## 15-minute Presentation

<a id="building-a-national-dataspace-testbed-infrastructure-foundations-for-trusted-data-exchange-in-australia"></a>
**Title:** Building a National Dataspace Testbed: Infrastructure Foundations for Trusted Data Exchange in Australia

**Abstract:** The International Data Spaces Association (IDSA) is a coalition of over 160 organisations across 28 countries that develops standards and technologies for secure, sovereign data sharing in data spaces, enabling trusted data exchange across industries while maintaining data ownership and control. The Australian Dataspaces Program, led by the ARDC (Australian Research Data Commons) in partnership with the IDSA, is establishing infrastructure and pilot projects to adapt IDSA's secure, sovereign data-sharing standards for trusted data exchange between research, industry, and government in Australia.

To support ARDC’s efforts in creating a dataspace ecosystem, RMIT RACE (RMIT Advanced Cloud Ecosystem) is collaborating with ARDC to develop an Australian prototype of a data space testbed service, leveraging the IDSA testbed distribution. Phase 1 of the project is expected to be completed in late 2025, with two objectives: 

1.	Establish and deploy an Australian prototype of an IDSA data space testbed service across multiple clouds (AWS and NeCTAR Cloud). This will provide testing and demonstration capabilities to underpin the ARDC’s work in creating a data space ecosystem and demonstrate data spaces' application to key ARDC use-cases for Australian researchers.

2.	Enhance the prototype data space testbed service by integrating with key Australian national research infrastructure, including the Australian Access Federation (AAF), Research Data Australia (RDA), and Research Vocabularies Australia (RVA). This involves developing a configurable testbed deployment process to create customised test data spaces on-demand for specific research use cases.

The anticipated key outcomes of the current project include: 
1.	Lowering the barriers for Australian research infrastructure providers who want to establish data spaces within Australia to test their ideas and prototypes.
2.	Establishing a demonstration capability that allows potential data space users and adopters to evaluate the benefits of a data space solution for their specific use case.
3.	Enabling Australian data space operators to assess available data space technologies for fitness-for-purpose against their priorities.

This presentation will share insights into the architectural design, deployment strategies, and integration challenges of building a national data space testbed. It will also highlight the benefits of a multi-cloud approach, and the lessons learned in aligning international data space standards with Australia’s existing research infrastructure landscape.

**Presenter Name:** Dr Robert Shen

**Bio:** Robert recieved his PhD from the School of Information Technology, University of Sydney, 2006. After that, he worked as a research fellow at the University of Melbourne, software lead & integration support at Australian National Data Service, and eResearch Director at Astronomy Australia Limited. Since January 2022, Robert has worked at RMIT University as the AWS Cloud Supercomputing Hub Director.

**Author names:** Shen, Robert*; Osborne, Dale; Taylor, Patrick; Cheng, Bohan; Dharmawardena, Kheeran; Chiu, Ben; Holewa, Hamish; Smillie, Jon; Ali, Muhammad; White, Andrew; Easton, Mark

---

## 15-minute Presentation

<a id="metrics-to-music-where-ai-meets-digital-classic"></a>
**Title:** Metrics to Music: Where AI Meets Digital Classic

**Abstract:**  Abstract 
The rise of computerization has transformed the literature and publishing industries; however, there remains a significant opportunity for research and development of computational tools that can assist in analysing and preserving classical works, particularly in Indian languages. This paper discusses one such computational tool that can support poets, publishers, and linguistic researchers in enhancing the quality of their work. Telugu (te-ISO 369, one of the Dravidian languages) metrical oriental literature is referred to as “Chandassu. " The Chandassu framework (metrical poetry) is prominent in Telugu literature and requires expertise in the oriental Telugu language and the computation of various rules. Even contemporary scholars of modern literature may not be fully aware of the comprehensive metrical system. Historical Telugu palm leaf literature is exclusively available in a metrical format, and conducting manual editing and analysis of this metrical poetry is considerably difficult. We describe how we have designed a machine-based verification and identification tool for Telugu Metrical Poetry (Chandassu), outlining the limitations within current research and the necessity for integration with other digital linguistic tools and languages. Additionally, we will present case studies involving an oriental poet and a publisher after this paper. 
Keywords: AI, Telugu, Metrical System, Machine Verification, Machine Identification


**Presenter Name:** Sree Ganesh Thottempudi

**Bio:** Post Doc at UNISA-South Africa

**Author names:** Thottempudi, Sree Ganesh; Mnkandla, Ernest

---

## 15-minute Presentation

<a id="accessible-and-extensible-design-for-statistical-computing-on-distributions"></a>
**Title:** Accessible and extensible design for statistical computing on distributions

**Abstract:** The uncertainty of model outputs is often absent or hidden in R, and tools for interacting with distributions are limited. For example, most prediction methods in R only produce point predictions by default. Although it is possible to obtain other parameters and form the complete distribution, additional knowledge about the distribution’s shape and properties are needed. The distributional package vastly simplifies creating and interacting with distributions in R. Using distributions as standalone vectors reduces makes statistical analysis more accessible with a user-friendly design that encourages accurate use of distributional statistic.

The package provides vectorised distributions through a collection of small, composable elements, enabling the calculation of various statistics without needing to use shape-specific p*/d*/q*/r* functions. Statistics can be easily calculated for distributions within the same vector, regardless of shape, and the modular infrastructure allows additional distributions or new statistical operations to be defined and integrated seamlessly. Manipulating distributions is also supported, including applying transformations, inflating values, truncating, and creating mixtures of distributions. When distributions are stored as data frame columns, these operations integrate seamlessly with tidyverse workflows. A growing number of research software engineers across many domains are using distributional as the foundation for their software. Notable examples include the ggdist extension package for visualising uncertainty in ggplot2, and the epiparameter package for infectious disease modelling.

**Presenter Name:** Mitchell O'Hara-Wild

**Bio:** Mitchell O'Hara-Wild (he/him) is a PhD candidate at Monash University, creating new techniques and tools for exploring and forecasting time series. He is the lead developer of the tidy time-series forecasting tools fable and feasts, and has co-developed the widely used forecast package since 2015. Mitchell is known for his user-friendly designs for statistical software, and he has recently been applying these design ideas to create vectorised data structures of distributions and time using vctrs.

**Author names:** O'Hara-Wild, Mitchell

---

## 15-minute Presentation

<a id="a-clearer-path-to-secure-authentication-pkce-and-oidc-explained"></a>
**Title:** A Clearer Path to Secure Authentication: PKCE and OIDC Explained

**Abstract:** Research software increasingly depends on secure, standards-based authentication. But for many developers, OpenID Connect flows (like PKCE) can seem arcane. This talk aims to make sense of the PKCE (Proof Key for Code Exchange) flow, explain why it exists, and help attendees decide when it’s worth implementing.

We’ll explore the core problems PKCE solves, and how it fits into authentication generally. Through examples grounded in typical research software contexts (browser-based tools, scripts, and services), we’ll outline scenarios where PKCE meaningfully improves security, and contrast them with cases where it may introduce unnecessary complexity.

We’ll also touch on how PKCE is relevant to identity federations (like the Australian Access Federation), and how shared infrastructure can reduce the effort required to “do auth right.”

No prior experience with OAuth or OpenID Connect is assumed: the session aims to be accessible to newcomers, while still offering useful insights for attendees familiar with the standards but unsure about best practices.

**Presenter Name:** Matthew Puku

**Bio:** I am Development Team Lead at Australian Access Federation, where I have worked for four years. Before that, I spent two years coding at a startup in the private sector, starting as an intern.

In my professional life, I love people, and simple solutions to complex problems. In my personal life, I am animated by faith and family, and am kept very, very busy by three young daughters.

**Author names:** Puku, Matthew

---

## Workshop

<a id="quick-tips-for-making-your-software-outlive-your-job"></a>
**Title:** Quick tips for making your software outlive your job

**Abstract:** Loss of key personnel has always been a risk for research software projects. Key members of a team may have to step away due to a change in national or university funding, due to illness or burnout, or because they are simply changing jobs. Today, political and financial changes are putting large numbers of researchers out of work simultaneously, both in NZ and abroad, potentially leaving large amounts of research software abandoned and destabilising necessary digital research infrastructure. We present ten tips to help researchers ensure that the software they have built will continue to be usable after they have left their present job, for any reason. These techniques, methods, and best practices were collectively sourced from researchers from dozens of universities across the globe, and are now being improved upon in a ReSA/CURIOSS Task Force. The tips shown here will enable individual researchers and labs to position their work in a way that makes it more sustainable and usable going forward, resulting in a more resilient research software ecosystem.

**Presenter Name:** Richard Littauer

**Bio:** Richard Littauer is a PhD student in Computer Science at Te Herenga Waka Victoria University of Wellington in Pōneke, Aotearoa New Zealand. His primary focus is understanding ecology and bird populations using computational modeling. His research interests beyond that involve open science, open source, community science platforms, and taxonomy. 

He is also an organizer for SustainOSS, and has recorded hundreds of podcasts on open source sustainability there. He is one of the two organizers of CURIOSS, the community for university and research institution open source program offices. He has been interested and involved in open source communities for decades.

**Author names:** Littauer, Richard

---

## Workshop

<a id="metavaluation-a-participatory-experiment-in-valuing-diverse-contributions-to-rsaa"></a>
**Title:** Metavaluation: A Participatory Experiment in Valuing Diverse Contributions to RSAA

**Abstract:** This workshop introduces Metavaluation, a participatory framework for assessing and rewarding the relative value of diverse ideas, activities, and resources contributed to any community. Originally developed to support the open science movement, Metavaluation generates transparent, interoperable metrics aligned with community values—supporting fair recognition, meaningful engagement, and decentralised coordination toward shared goals.

Together, we’ll use RSAA25 as a living case study. Participants will nominate real contributions to the conference—such as workshops, talks, mentoring, and behind-the-scenes efforts—then assess their value through a simple, inclusive peer-review process using an open-source platform developed by Open Heart + Mind (OHM), a nonprofit citizen science community. This will generate a shared value map: a live visualisation of what the RSAA community values most, offering feedback that can inform future events, governance, and collaboration within and beyond the conference.

The resulting data will be presented during a 15-minute talk the following day, showcasing the framework’s potential for rapid iteration and dynamic evolution. We’ll close the workshop with shared reflections and a discussion on how this approach could empower software communities to better recognise, coordinate, and sustain their most meaningful work. 

**Presenter Name:** Cooper Smout

**Bio:** Dr. Cooper Smout is a designer, neuroscientist, and open science entrepreneur working at the intersection of collective intelligence, participatory governance, and cultural change. With a background in architecture and a PhD in the neuroscience of consciousness, he left academia to found Free Our Knowledge, a collective action platform for open research, and Open Heart + Mind (OHM), a nonprofit organisation developing open-source tools to empower communities. His current work focuses on Metavaluation, a participatory evaluation framework that generates transparent, interoperable value metrics to support fair recognition and reward, decentralised coordination, and collective governance across research and commons-oriented ecosystems.

**Author names:** Smout, Cooper

---





